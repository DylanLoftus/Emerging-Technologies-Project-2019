{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Model with Keras\n",
    "With this model we have to read in bytes from a file. The file type we are working with has the extension .gz and this file type can be unzipped with gzip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import gzip to unzip the file.\n",
    "import gzip\n",
    "\n",
    "# Open the byte image file and put it in a file called file.\n",
    "with gzip.open('t10k-images-idx3-ubyte.gz', 'rb') as file:\n",
    "    # Read the contents of the file into a variable named 'file_content'\n",
    "    file_content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tells us what type of data is in the file.\n",
    "type(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x00\\x00\\x08\\x03'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_content[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read one image from the File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = file_content[16:800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy and call it np.\n",
    "import numpy as np\n",
    "\n",
    "# Make an array with the content from the file into an array with 28 rows and 28 columns.\n",
    "image = ~np.array(list(I)).reshape(28,28).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2a0898d9208>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAANMElEQVR4nO3df6hc9ZnH8c9nNVEwEZLNVaONmxpFDIppGcKqS3WVDTEI2j+6JEjJgmwKKqRQdMVFq/hP2GxTCkpJotJ06VqKqRokrJVQ0fwTMjFRo2HXX/lVL7k3RqgBoZo8+8c97l7jnTPjnJk5kzzvF1xm5jxzznky3E/OufM9M19HhACc+f6q7gYADAZhB5Ig7EAShB1IgrADSZw9yJ3NmTMn5s+fP8hdAqns379fR48e9VS1SmG3vVTSLySdJenJiFhT9vz58+er2WxW2SWAEo1Go2Wt69N422dJekLSrZIWSlphe2G32wPQX1X+Zl8s6b2I+CAi/iLpt5Ju701bAHqtStgvkXRo0uPDxbKvsL3KdtN2c3x8vMLuAFRRJexTvQnwtWtvI2JDRDQiojEyMlJhdwCqqBL2w5LmTXr8LUkfVWsHQL9UCftOSVfY/rbt6ZKWS9rSm7YA9FrXQ28R8YXteyW9pImht6cj4u2edQagpyqNs0fEVklbe9QLgD7iclkgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEpWmbLa9X9Knkk5I+iIiGr1oCkDvVQp74e8j4mgPtgOgjziNB5KoGvaQ9Afbu2yvmuoJtlfZbtpujo+PV9wdgG5VDfsNEfFdSbdKusf29059QkRsiIhGRDRGRkYq7g5AtyqFPSI+Km7HJD0naXEvmgLQe12H3fZ5tmd+eV/SEkl7e9UYgN6q8m78hZKes/3ldv4zIv6rJ10B6Lmuwx4RH0i6toe9AOgjht6AJAg7kARhB5Ig7EAShB1IohcfhEnh2WefbVnbuHFj6boXX3xxaf3cc88trd95552l9Ysuuqhl7fLLLy9dF3lwZAeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhn79B9993XsnbgwIG+7nv9+vWl9ZkzZ7asLVy4sNftnDbmzZvXsnb//feXrttonHlflMyRHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJy9Q08++WTL2htvvFG6brux7nfeeae0vnv37tL6K6+80rK2Y8eO0nXLxqIl6dChQ6X1Ks4+u/zXr90MQqOjo6X1sn/7pZdeWrou4+wATluEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+wduuWWW7qqdWLp0qWV1v/kk09a1tqN0bcbT965c2dXPXXinHPOKa1feeWVpfWrrrqqtH7s2LGWtcsuu6x03TNR2yO77adtj9neO2nZbNsv2363uJ3V3zYBVNXJafyvJJ166HlA0raIuELStuIxgCHWNuwR8aqkU8+Hbpe0qbi/SdIdPe4LQI91+wbdhRExKknF7QWtnmh7le2m7eb4+HiXuwNQVd/fjY+IDRHRiIhGuw82AOifbsN+xPZcSSpux3rXEoB+6DbsWyStLO6vlPRCb9oB0C9tx9ltPyPpJklzbB+W9FNJayT9zvZdkg5K+kE/m0S5WbNaj3zefPPNlbZd9RqCKjZv3lxaL7u+QJKuueaalrXly5d31dPprG3YI2JFi1J9vwUAvjEulwWSIOxAEoQdSIKwA0kQdiAJPuKK2oyNlV+Ldffdd5fWT548WVp/+OGHW9Zmz55duu6ZiCM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBODtq88QTT5TW232NWdlHe6X2X0WdDUd2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcXb01fbt21vW1qxZU2nbzz//fGn96quvrrT9Mw1HdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnF29NXWrVtb1j7//PPSddtNF33dddd11VNWbY/stp+2PWZ776Rlj9j+k+09xc+y/rYJoKpOTuN/JWnpFMt/HhGLip/W/30DGAptwx4Rr0o6NoBeAPRRlTfo7rX9ZnGa3/LLwGyvst203Wz3nWIA+qfbsP9S0gJJiySNSvpZqydGxIaIaEREY2RkpMvdAaiqq7BHxJGIOBERJyVtlLS4t20B6LWuwm577qSH35e0t9VzAQyHtuPstp+RdJOkObYPS/qppJtsL5IUkvZL+lEfe8QQ++yzz0rrL730Usva9OnTS9d99NFHS+vTpk0rreOr2oY9IlZMsfipPvQCoI+4XBZIgrADSRB2IAnCDiRB2IEk+IgrKlm7dm1pfffu3S1rS5dO9fmq/3f99dd31ROmxpEdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnB2lXnzxxdL6Y489Vlo///zzW9YeeuihrnpCdziyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjLMn9/HHH5fWV69eXVo/ceJEaX3ZstYT/DLl8mBxZAeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnP8O1Gwdv993tH374YWl9wYIFpfV2n3fH4LQ9stueZ/uPtvfZftv26mL5bNsv2363uJ3V/3YBdKuT0/gvJP0kIq6S9LeS7rG9UNIDkrZFxBWSthWPAQyptmGPiNGIeL24/6mkfZIukXS7pE3F0zZJuqNfTQKo7hu9QWd7vqTvSNoh6cKIGJUm/kOQdEGLdVbZbtpujo+PV+sWQNc6DrvtGZI2S/pxRPy50/UiYkNENCKiMTIy0k2PAHqgo7DbnqaJoP8mIn5fLD5ie25RnytprD8tAuiFtkNvti3pKUn7ImLdpNIWSSslrSluX+hLh6jk/fffL63v2rWr0vbXrVtXWm83NIfB6WSc/QZJP5T0lu09xbIHNRHy39m+S9JBST/oT4sAeqFt2CNiuyS3KN/S23YA9AuXywJJEHYgCcIOJEHYgSQIO5AEH3E9Axw4cKBlbcmSJZW2vXbt2tL6bbfdVmn7GByO7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOPsZ4D169e3rB08eLDStm+88cbS+sTXHeB0wJEdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnP008Nprr5XWH3/88QF1gtMZR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSKKT+dnnSfq1pIsknZS0ISJ+YfsRSf8sabx46oMRsbVfjWa2ffv20vrx48e73na7+dNnzJjR9bYxXDq5qOYLST+JiNdtz5S0y/bLRe3nEfHv/WsPQK90Mj/7qKTR4v6ntvdJuqTfjQHorW/0N7vt+ZK+I2lHsehe22/aftr2rBbrrLLdtN0cHx+f6ikABqDjsNueIWmzpB9HxJ8l/VLSAkmLNHHk/9lU60XEhohoRERjZGSkBy0D6EZHYbc9TRNB/01E/F6SIuJIRJyIiJOSNkpa3L82AVTVNuye+PrQpyTti4h1k5bPnfS070va2/v2APRKJ+/G3yDph5Lesr2nWPagpBW2F0kKSfsl/agvHaKSa6+9trS+bdu20vrs2bN72Q5q1Mm78dslTfXl4IypA6cRrqADkiDsQBKEHUiCsANJEHYgCcIOJOGIGNjOGo1GNJvNge0PyKbRaKjZbE45jzZHdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IYqDj7LbHJR2YtGiOpKMDa+CbGdbehrUvid661cve/iYipvz+t4GG/Ws7t5sR0aitgRLD2tuw9iXRW7cG1Run8UAShB1Iou6wb6h5/2WGtbdh7Uuit24NpLda/2YHMDh1H9kBDAhhB5KoJey2l9r+b9vv2X6gjh5asb3f9lu299iu9cP3xRx6Y7b3Tlo22/bLtt8tbqecY6+m3h6x/afitdtje1lNvc2z/Ufb+2y/bXt1sbzW166kr4G8bgP/m932WZL+R9I/SDosaaekFRHxzkAbacH2fkmNiKj9Agzb35N0XNKvI+LqYtm/SToWEWuK/yhnRcS/DElvj0g6Xvc03sVsRXMnTzMu6Q5J/6QaX7uSvv5RA3jd6jiyL5b0XkR8EBF/kfRbSbfX0MfQi4hXJR07ZfHtkjYV9zdp4pdl4Fr0NhQiYjQiXi/ufyrpy2nGa33tSvoaiDrCfomkQ5MeH9Zwzfcekv5ge5ftVXU3M4ULI2JUmvjlkXRBzf2cqu003oN0yjTjQ/PadTP9eVV1hH2q78capvG/GyLiu5JulXRPcbqKznQ0jfegTDHN+FDodvrzquoI+2FJ8yY9/pakj2roY0oR8VFxOybpOQ3fVNRHvpxBt7gdq7mf/zNM03hPNc24huC1q3P68zrCvlPSFba/bXu6pOWSttTQx9fYPq9440S2z5O0RMM3FfUWSSuL+yslvVBjL18xLNN4t5pmXDW/drVPfx4RA/+RtEwT78i/L+lf6+ihRV+XSXqj+Hm77t4kPaOJ07rPNXFGdJekv5a0TdK7xe3sIertPyS9JelNTQRrbk29/Z0m/jR8U9Ke4mdZ3a9dSV8Ded24XBZIgivogCQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJ/wWw2+zvAHeDNgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the image.\n",
    "plt.imshow(image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading a Label from the Labels File."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to import gzip again.\n",
    "import gzip\n",
    "\n",
    "# Use gzip to open the labels folder and call it file.\n",
    "with gzip.open('t10k-labels-idx1-ubyte.gz', 'rb') as file:\n",
    "    # Read the contents of the file into a variable named labels.\n",
    "    labels = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the byte to an int.\n",
    "int.from_bytes(labels[8:9], byteorder=\"big\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now create a Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to import Keras as Keras is used to make our Model.\n",
    "import keras as kr\n",
    "\n",
    "# We're going to build a sequential neural network.\n",
    "model = kr.models.Sequential()\n",
    "\n",
    "# Add a hidden layer which contains 1000 neurons and set the input layer with 784.\n",
    "model.add(kr.layers.Dense(units=600, activation='linear', input_dim=784))\n",
    "model.add(kr.layers.Dense(units=400, activation='relu'))\n",
    "# Add a three neuron output layer.\n",
    "model.add(kr.layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "# Build the graph.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "# Use gzip to open the training images file.\n",
    "with gzip.open('train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    train_img = f.read()\n",
    "\n",
    "# Use gzip to open the training labels file.\n",
    "with gzip.open('train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    train_lbl = f.read()\n",
    "\n",
    "# Convert the data to arrays.\n",
    "train_img = ~np.array(list(train_img[16:])).reshape(60000, 28, 28).astype(np.uint8) / 255.0\n",
    "train_lbl =  np.array(list(train_lbl[ 8:])).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place all the training images into input\n",
    "inputs = train_img.reshape(60000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 [0 0 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# For encoding categorical variables.\n",
    "import sklearn.preprocessing as pre\n",
    "\n",
    "encoder = pre.LabelBinarizer()\n",
    "encoder.fit(train_lbl)\n",
    "outputs = encoder.transform(train_lbl)\n",
    "\n",
    "print(train_lbl[0], outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[1 0 0 0 0 0 0 0 0 0]]\n",
      "1 [[0 1 0 0 0 0 0 0 0 0]]\n",
      "2 [[0 0 1 0 0 0 0 0 0 0]]\n",
      "3 [[0 0 0 1 0 0 0 0 0 0]]\n",
      "4 [[0 0 0 0 1 0 0 0 0 0]]\n",
      "5 [[0 0 0 0 0 1 0 0 0 0]]\n",
      "6 [[0 0 0 0 0 0 1 0 0 0]]\n",
      "7 [[0 0 0 0 0 0 0 1 0 0]]\n",
      "8 [[0 0 0 0 0 0 0 0 1 0]]\n",
      "9 [[0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "     print(i, encoder.transform([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.5252 - accuracy: 0.8427\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.2365 - accuracy: 0.9270\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.1859 - accuracy: 0.9426\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.1578 - accuracy: 0.9510\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.1429 - accuracy: 0.9569\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.1369 - accuracy: 0.9570\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.1207 - accuracy: 0.9625\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.1165 - accuracy: 0.9645\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.1095 - accuracy: 0.9664\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.1024 - accuracy: 0.9694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2a08ca5c908>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with the inputs and the outputs\n",
    "# Pass over the dataset ten times 'epochs=10'\n",
    "model.fit(inputs, outputs, epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    test_img = f.read()\n",
    "\n",
    "with gzip.open('t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    test_lbl = f.read()\n",
    "    \n",
    "test_img = ~np.array(list(test_img[16:])).reshape(10000, 784).astype(np.uint8) / 255.0\n",
    "test_lbl =  np.array(list(test_lbl[ 8:])).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9671"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(encoder.inverse_transform(model.predict(test_img)) == test_lbl).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.7386872e-07, 4.7743782e-08, 1.7212006e-06, 6.0176375e-10,\n",
       "        9.9816030e-01, 3.0585101e-09, 4.0521904e-06, 4.0328991e-06,\n",
       "        2.8831242e-09, 1.8294962e-03]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make output predictions based on the input which in this case is (test_img[4:5])\n",
    "model.predict(test_img[4:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2a08cdc0508>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show image at index 4 in the array and reshape the plot to a 28 x 28 array\n",
    "plt.imshow(test_img[4].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model so you don't have to train it every time.\n",
    "model.save('saved_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
